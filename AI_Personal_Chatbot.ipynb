{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gfz1NE7O1tuH",
        "outputId": "db07ac27-24ed-40be-864b-72dea3fd7ea5"
      },
      "outputs": [],
      "source": [
        "!pip install langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "xzCVpRjzDKIO",
        "outputId": "d341c44a-63a5-4af4-9ddd-fe20ca1ca740"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "LmKDv4c2PJIJ",
        "outputId": "a0df3d9d-f08d-4f7c-be58-04b00cd803a4"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_community pinecone langchain_pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "gL7U2vyRC_Rq"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.agents import initialize_agent, AgentExecutor\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from pinecone import Pinecone\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from pinecone import ServerlessSpec\n",
        "from langchain.tools import Tool\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8zDu7RyBWqo"
      },
      "outputs": [],
      "source": [
        "GEMENI_API_KEY = ''\n",
        "pinecone_api_key = ''\n",
        "weather_API_KEY = ''\n",
        "ALPHA_VANTAGE_APIKEY = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "avriOAiqB5hc"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=GEMENI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VEGHo1MtQ98W"
      },
      "outputs": [],
      "source": [
        "#Load text file\n",
        "loader = TextLoader(\"Personal_Details.txt\")\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sdWCC7cSSrx",
        "outputId": "4783b476-d7bd-48f3-ee33-9b3d292a9719"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dimension': 768,\n",
              " 'index_fullness': 0.0,\n",
              " 'metric': 'cosine',\n",
              " 'namespaces': {'': {'vector_count': 13}},\n",
              " 'total_vector_count': 13,\n",
              " 'vector_type': 'dense'}"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=pinecone_api_key)\n",
        "index_name = \"chatbot-index-gemini\"\n",
        "\n",
        "if not pc.has_index(index_name):\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        # dimension of the vector embeddings produced by gemini-embedding-001\n",
        "        dimension=768, #dimension=768-small, 1536-medium, 3072-large\n",
        "        metric=\"cosine\",\n",
        "        # parameters for the free tier index\n",
        "        spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Initialize index client\n",
        "index = pc.Index(name=index_name)\n",
        "\n",
        "# View index stats\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tBvb9RyoTarP"
      },
      "outputs": [],
      "source": [
        "splitter = RecursiveCharacterTextSplitter(chunk_size = 200, chunk_overlap = 50)\n",
        "all_splits = splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSngaaUDTjaS",
        "outputId": "7f1980dd-ab35-4bce-8e6d-e93da975b728"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='Ajay Bellamkonda, fondly known as Ajay, is a passionate Data Engineer from Hyderabad, India, originally hailing from Challapalli. Born on May 3, 1992, he is an Indian national and a proud Hindu who' metadata={'source': 'Personal_Details.txt'}\n"
          ]
        }
      ],
      "source": [
        "print(all_splits[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MQCeQyMoTvA9",
        "outputId": "22c49fce-4e47-4a99-9d4f-489307748bf9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['doc_0',\n",
              " 'doc_1',\n",
              " 'doc_2',\n",
              " 'doc_3',\n",
              " 'doc_4',\n",
              " 'doc_5',\n",
              " 'doc_6',\n",
              " 'doc_7',\n",
              " 'doc_8',\n",
              " 'doc_9',\n",
              " 'doc_10',\n",
              " 'doc_11',\n",
              " 'doc_12']"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GEMENI_API_KEY)\n",
        "\n",
        "vectorstore = PineconeVectorStore(index=index, embedding=embeddings)\n",
        "\n",
        "ids = [f\"doc_{i}\" for i in range(len(all_splits))]\n",
        "\n",
        "vectorstore.add_documents(documents=all_splits, ids=ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lyaYDakPv3OX"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\":3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "9CwIjfqiwWDy"
      },
      "outputs": [],
      "source": [
        "def personal_info_tool(query : str) -> str :\n",
        "  \"\"\" Retrieve Ajay's information and generate natural answer\"\"\"\n",
        "  results = retriever.invoke(query)\n",
        "  #print(query)\n",
        "\n",
        "  if not results:\n",
        "    return \"I am not able to find personal information about that\"\n",
        "\n",
        "  context = \"\\n\".join([doc.page_content for doc in results])\n",
        "  prompt = f\"You are Ajay's assistant. Based on the following context, answer the question:\\n\\n{context}\\n\\nQuestion: {query}\"\n",
        "  #print(prompt)\n",
        "  response = llm.invoke(prompt)\n",
        "\n",
        "  return response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "Ixghw3dDT23k"
      },
      "outputs": [],
      "source": [
        "def get_weather_report(location: str) -> str:\n",
        "    \"\"\"Fetch current weather for a given location using OpenWeatherMap API.\"\"\"\n",
        "    api_key = weather_API_KEY\n",
        "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={location}&appid={api_key}&units=metric\"\n",
        "\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        return f\"Couldn't fetch weather for {location}. Please check the location name.\"\n",
        "\n",
        "    data = response.json()\n",
        "    temp = data[\"main\"][\"temp\"]\n",
        "    condition = data[\"weather\"][0][\"description\"]\n",
        "    return f\"The current temperature in {location} is {temp}Â°C with {condition}.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "Op_D7y8fZdYM"
      },
      "outputs": [],
      "source": [
        "def get_stock_price(symbol: str) -> str:\n",
        "    \"\"\"Fetch the latest stock price for a given symbol using Alpha Vantage.\"\"\"\n",
        "    api_key = ALPHA_VANTAGE_APIKEY\n",
        "    url = f\"https://www.alphavantage.co/query\"\n",
        "    params = {\n",
        "        \"function\": \"GLOBAL_QUOTE\",\n",
        "        \"symbol\": symbol,\n",
        "        \"apikey\": api_key\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, params=params)\n",
        "    if response.status_code != 200:\n",
        "        return f\"Error fetching data for {symbol}. Status code: {response.status_code}\"\n",
        "\n",
        "    data = response.json()\n",
        "    try:\n",
        "        quote = data[\"Global Quote\"]\n",
        "        price = quote[\"05. price\"]\n",
        "        change = quote[\"10. change percent\"]\n",
        "        return f\"{symbol} is currently trading at ${price} ({change} change).\"\n",
        "    except KeyError:\n",
        "        return f\"No data found for symbol: {symbol}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "04b9g3trySEl"
      },
      "outputs": [],
      "source": [
        "#tools = [Tool(name = \"PersonalInfoRetriever\", func = personal_info_tool,\n",
        "#              description= (\"Use this tool to answer any question about Ajay Bellamkonda, including his education, work experience, personal background, or achievements.\"))]\n",
        "PersonalInfoRetriever_tools = Tool(name = \"PersonalInfoRetriever\", func = personal_info_tool, description= \"Use this tool to answer any question about Ajay Bellamkonda, including his education, work experience, personal background, or achievements.\")\n",
        "\n",
        "weather_tool = Tool(name=\"WeatherFetcher\", func=get_weather_report, description=\"Use this tool to get the current weather for any city.\")\n",
        "\n",
        "stock_tool = Tool(name=\"StockPriceFetcher\", func=get_stock_price, description=\"Use this tool to get the latest stock price for a company. Input should be a stock symbol like AAPL or TSLA.\")\n",
        "\n",
        "tools = [PersonalInfoRetriever_tools,weather_tool,stock_tool]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "ma7114np0AXE"
      },
      "outputs": [],
      "source": [
        "agent_executor = initialize_agent(tools=tools, llm=llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "MA8jSkX60w_9"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "  input : str\n",
        "  output : str\n",
        "\n",
        "def call_agent(state:AgentState):\n",
        "  result = agent_executor.invoke({\"input\" : state[\"input\"]})\n",
        "  return {\"output\" : result[\"output\"]}\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"agent\", call_agent)\n",
        "workflow.set_entry_point(\"agent\")\n",
        "workflow.add_edge(\"agent\",END)\n",
        "\n",
        "\n",
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nADD9wZG2XqM",
        "outputId": "1fd8f52a-6ed0-4908-e12d-f7e9c960b816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "you: what is the educational qualification of Ajay?\n",
            "Bot:  Ajay Bellamkonda completed his B.Tech from KKR & KSR Institute of Engineering and Technology, Ganguru, in 2014 with an aggregate of 81%.\n",
            "you: what is the stock price of MSFT today ?\n",
            "Bot:  The stock price of MSFT is currently trading at $505.7200 (-0.7945% change).\n",
            "you: How is the weather in hyderabad today ?\n",
            "Bot:  The current temperature in Hyderabad is 29.23Â°C with haze.\n",
            "you: What is the capital of India ?\n",
            "Bot:  New Delhi\n",
            "you: what is Ajay's home town ?\n",
            "Bot:  Ajay Bellamkonda's hometown is Challapalli.\n",
            "you: What are his educational qualifications ?\n",
            "Bot:  Ajay Bellamkonda has a Masterâs degree (M.Tech) in Electronics and Communication from IIIT Nuzvidu and a Bachelor's Degree from Engineering and Technology, Ganguru, completed in 2014 with an aggregate of 81%.\n",
            "you: quit\n",
            "Bot: Good Bye\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "  query = input(\"you: \")\n",
        "  if query.lower() in [\"exit\",\"quit\"]:\n",
        "    print(\"Bot: Good Bye\")\n",
        "    break\n",
        "  result = app.invoke(({\"input\": query}))\n",
        "  print(\"Bot: \", result[\"output\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
